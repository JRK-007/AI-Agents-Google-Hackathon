{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JRK-007/AI-Agents-Google-Hackathon/blob/main/AI_AGENTS_HACKATHON.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2mRJQY-NgcF"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "supplychain_eye.py\n",
        "\n",
        "SupplyChain-Eye: Multi-Agent Logistics Routing & Anomaly Detection Assistant\n",
        "- Single-file demo agent system\n",
        "- No API keys required (uses DummyLLMClient). Replace with real LLM client in production.\n",
        "- Demonstrates: Multi-agent flows, tools (code exec), sessions & memory, context compaction,\n",
        "  observability, agent evaluation, A2A protocol, pause/resume (checkpointing).\n",
        "\n",
        "Author: Generated for Kaggle Agents Capstone (Freestyle Track)\n",
        "\"\"\"\n",
        "\n",
        "import asyncio\n",
        "import json\n",
        "import math\n",
        "import logging\n",
        "import os\n",
        "import time\n",
        "import uuid\n",
        "from collections import defaultdict, deque\n",
        "from copy import deepcopy\n",
        "from datetime import datetime\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "# -----------------------\n",
        "# Basic configuration\n",
        "# -----------------------\n",
        "LOG = logging.getLogger(\"SupplyChainEye\")\n",
        "LOG.setLevel(logging.DEBUG)\n",
        "handler = logging.StreamHandler()\n",
        "fmt = logging.Formatter(\"%(asctime)s [%(levelname)s] %(trace_id)s %(name)s: %(message)s\")\n",
        "handler.setFormatter(fmt)\n",
        "LOG.addHandler(handler)\n",
        "\n",
        "# helper to inject trace_id into logs\n",
        "def log_with_trace(trace_id, level, msg, **kwargs):\n",
        "    extra = {\"trace_id\": trace_id}\n",
        "    LOG.log(level, msg, extra=extra, **kwargs)\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Utilities & Tools\n",
        "# -----------------------\n",
        "\n",
        "def haversine_km(a: Tuple[float, float], b: Tuple[float, float]) -> float:\n",
        "    \"\"\"Haversine distance in kilometers between two (lat, lon).\"\"\"\n",
        "    lat1, lon1 = a\n",
        "    lat2, lon2 = b\n",
        "    R = 6371.0\n",
        "    phi1 = math.radians(lat1)\n",
        "    phi2 = math.radians(lat2)\n",
        "    dphi = math.radians(lat2 - lat1)\n",
        "    dlambda = math.radians(lon2 - lon1)\n",
        "    x = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2\n",
        "    return 2*R*math.asin(math.sqrt(x))\n",
        "\n",
        "\n",
        "class ToolExecutor:\n",
        "    \"\"\"\n",
        "    Built-in tool for code execution / deterministic models.\n",
        "    Method calls are synchronous and deterministic; used for distance, ETA, fuel estimates.\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def compute_trip_metrics(path: List[Tuple[float, float]], speed_kmh: float = 40.0, stops_minutes: float = 10.0):\n",
        "        total_km = 0.0\n",
        "        total_time_h = 0.0\n",
        "        for i in range(len(path)-1):\n",
        "            d = haversine_km(path[i], path[i+1])\n",
        "            total_km += d\n",
        "            total_time_h += d / speed_kmh\n",
        "        # add stops\n",
        "        total_time_h += (len(path)-1) * (stops_minutes/60.0)\n",
        "        # simplified fuel model (liters per 100 km)\n",
        "        fuel_efficiency = 8.0  # L/100km baseline\n",
        "        fuel_liters = total_km * (fuel_efficiency/100.0)\n",
        "        return {\"km\": total_km, \"time_h\": total_time_h, \"fuel_liters\": fuel_liters}\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# LLM Client Interface\n",
        "# -----------------------\n",
        "\n",
        "class LLMClient:\n",
        "    \"\"\"\n",
        "    Abstract LLM client interface. Implement send(context, prompt) -> dict\n",
        "    Must return dict with keys: 'text' and optionally 'structured' (json).\n",
        "    \"\"\"\n",
        "    async def send(self, context: str, prompt: str) -> Dict[str, Any]:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class DummyLLMClient(LLMClient):\n",
        "    \"\"\"Simple deterministic 'LLM' for testing without network.\"\"\"\n",
        "    async def send(self, context: str, prompt: str) -> Dict[str, Any]:\n",
        "        # Very primitive deterministic responses based on prompt cues.\n",
        "        await asyncio.sleep(0.2)\n",
        "        if \"classify\" in prompt.lower() or \"detect\" in prompt.lower():\n",
        "            # simulate classification\n",
        "            return {\"text\": \"anomaly_detected:high_idle_time;recommendation:investigate_loading;confidence:0.90\",\n",
        "                    \"structured\": {\"anomaly\": \"high_idle_time\", \"recommendation\": \"investigate_loading\", \"confidence\": 0.9}}\n",
        "        if \"optimize\" in prompt.lower() or \"re-route\" in prompt.lower():\n",
        "            return {\"text\": \"suggested:reassign_stop_3_to_truck_2;eta_reduction:0.24;fuel_saving_l:3.2\",\n",
        "                    \"structured\": {\"action\":\"reassign_stop_3_to_truck_2\",\"eta_reduction_h\":0.24,\"fuel_saving_l\":3.2}}\n",
        "        # default summarize\n",
        "        return {\"text\": \"summary: no major issues found;confidence:0.75\", \"structured\": {\"summary\":\"no major issues\",\"confidence\":0.75}}\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Session & Memory\n",
        "# -----------------------\n",
        "\n",
        "class InMemorySessionService:\n",
        "    \"\"\"\n",
        "    Simple session management. Sessions can be checkpointed to disk to pause/resume long runs.\n",
        "    \"\"\"\n",
        "    def __init__(self, storage_dir=\"sessions\"):\n",
        "        self.sessions: Dict[str, Dict[str, Any]] = {}\n",
        "        os.makedirs(storage_dir, exist_ok=True)\n",
        "        self.storage_dir = storage_dir\n",
        "\n",
        "    def create_session(self, session_id: Optional[str] = None):\n",
        "        session_id = session_id or str(uuid.uuid4())\n",
        "        self.sessions[session_id] = {\"created_at\": time.time(), \"history\": [], \"state\": {}}\n",
        "        return session_id\n",
        "\n",
        "    def get(self, session_id: str):\n",
        "        return self.sessions.get(session_id)\n",
        "\n",
        "    def append_history(self, session_id: str, entry: Dict[str, Any]):\n",
        "        self.sessions[session_id][\"history\"].append(entry)\n",
        "\n",
        "    def save(self, session_id: str):\n",
        "        path = os.path.join(self.storage_dir, f\"{session_id}.json\")\n",
        "        with open(path, \"w\") as f:\n",
        "            json.dump(self.sessions[session_id], f, default=str)\n",
        "        return path\n",
        "\n",
        "    def load(self, session_id: str):\n",
        "        path = os.path.join(self.storage_dir, f\"{session_id}.json\")\n",
        "        if not os.path.exists(path):\n",
        "            raise FileNotFoundError(path)\n",
        "        with open(path, \"r\") as f:\n",
        "            self.sessions[session_id] = json.load(f)\n",
        "        return self.sessions[session_id]\n",
        "\n",
        "\n",
        "class MemoryBank:\n",
        "    \"\"\"\n",
        "    Persistent memory for long term patterns (simple JSON store).\n",
        "    Stores historical metrics for comparison and compaction.\n",
        "    \"\"\"\n",
        "    def __init__(self, filename=\"memory_bank.json\"):\n",
        "        self.filename = filename\n",
        "        if os.path.exists(filename):\n",
        "            with open(filename, \"r\") as f:\n",
        "                self.store = json.load(f)\n",
        "        else:\n",
        "            self.store = {\"runs\": []}\n",
        "\n",
        "    def record_run(self, metadata: Dict[str, Any]):\n",
        "        self.store[\"runs\"].append(metadata)\n",
        "        with open(self.filename, \"w\") as f:\n",
        "            json.dump(self.store, f, default=str)\n",
        "\n",
        "    def compact_context(self, last_n=5):\n",
        "        # returns a compact summary of last N runs\n",
        "        runs = self.store.get(\"runs\", [])\n",
        "        recent = runs[-last_n:]\n",
        "        # do a simple aggregation\n",
        "        if not recent:\n",
        "            return \"No prior runs\"\n",
        "        avg_eta = sum(r.get(\"total_time_h\", 0) for r in recent)/len(recent)\n",
        "        avg_fuel = sum(r.get(\"fuel_liters\", 0) for r in recent)/len(recent)\n",
        "        return f\"Recent {len(recent)} runs: avg_eta_h={avg_eta:.2f}, avg_fuel_l={avg_fuel:.2f}\"\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# A2A Protocol\n",
        "# -----------------------\n",
        "def make_message(sender: str, recipient: str, intent: str, payload: Dict[str, Any], trace_id: Optional[str] = None):\n",
        "    return {\n",
        "        \"message_id\": str(uuid.uuid4()),\n",
        "        \"timestamp\": datetime.utcnow().isoformat(),\n",
        "        \"trace_id\": trace_id or str(uuid.uuid4()),\n",
        "        \"sender\": sender,\n",
        "        \"recipient\": recipient,\n",
        "        \"intent\": intent,\n",
        "        \"payload\": payload\n",
        "    }\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Observability / Metrics\n",
        "# -----------------------\n",
        "\n",
        "class Observability:\n",
        "    def __init__(self):\n",
        "        self.metrics = defaultdict(int)\n",
        "        self.logs = []\n",
        "\n",
        "    def incr(self, metric_name: str, amount: int = 1):\n",
        "        self.metrics[metric_name] += amount\n",
        "\n",
        "    def record_log(self, trace_id: str, event: str, details: Dict[str, Any]):\n",
        "        self.logs.append({\"trace_id\": trace_id, \"event\": event, \"details\": details, \"time\": datetime.utcnow().isoformat()})\n",
        "        log_with_trace(trace_id, logging.INFO, f\"Event={event} details={details}\")\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Base Agent\n",
        "# -----------------------\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, name: str, llm: LLMClient, session_service: InMemorySessionService, memory: MemoryBank, obs: Observability):\n",
        "        self.name = name\n",
        "        self.llm = llm\n",
        "        self.session = session_service\n",
        "        self.memory = memory\n",
        "        self.obs = obs\n",
        "        self.inbox = asyncio.Queue()\n",
        "        self.running = False\n",
        "\n",
        "    async def send(self, msg: Dict[str, Any]):\n",
        "        await self.inbox.put(msg)\n",
        "\n",
        "    async def handle_message(self, msg: Dict[str, Any]):\n",
        "        \"\"\"Override\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    async def run(self):\n",
        "        self.running = True\n",
        "        while self.running:\n",
        "            try:\n",
        "                msg = await asyncio.wait_for(self.inbox.get(), timeout=1.0)\n",
        "            except asyncio.TimeoutError:\n",
        "                # loop agent behavior can be implemented by subclass\n",
        "                await asyncio.sleep(0.05)\n",
        "                continue\n",
        "            trace_id = msg.get(\"trace_id\", str(uuid.uuid4()))\n",
        "            self.obs.record_log(trace_id, f\"{self.name}.received\", {\"msg_id\": msg.get(\"message_id\"), \"intent\": msg.get(\"intent\")})\n",
        "            try:\n",
        "                await self.handle_message(msg)\n",
        "            except Exception as e:\n",
        "                log_with_trace(trace_id, logging.ERROR, f\"Agent {self.name} failed: {e}\")\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Agents Implementation\n",
        "# -----------------------\n",
        "\n",
        "class DataIntakeAgent(Agent):\n",
        "    \"\"\"\n",
        "    Ingests shipments/trips: accepts a payload like:\n",
        "    {\n",
        "      \"shipments\": [\n",
        "        {\"id\":\"s1\",\"path\":[(lat,lon),(lat,lon),...],\"vehicle\":\"truckA\",\"timestamp\":\"...\"},\n",
        "        ...\n",
        "      ],\n",
        "      \"constraints\": {...}\n",
        "    }\n",
        "    Produces a standardized session state and emits to RouteAnalyzer\n",
        "    \"\"\"\n",
        "    async def handle_message(self, msg: Dict[str, Any]):\n",
        "        trace_id = msg[\"trace_id\"]\n",
        "        payload = msg[\"payload\"]\n",
        "        session_id = payload.get(\"session_id\") or self.session.create_session()\n",
        "        self.obs.incr(\"data_intake_msgs\")\n",
        "        # Standardize the input\n",
        "        shipments = payload.get(\"shipments\", [])\n",
        "        standardized = []\n",
        "        for s in shipments:\n",
        "            standard = {\n",
        "                \"id\": s[\"id\"],\n",
        "                \"path\": s.get(\"path\"),\n",
        "                \"vehicle\": s.get(\"vehicle\", \"truck\"),\n",
        "                \"speed_kmh\": s.get(\"speed_kmh\", 40.0),\n",
        "                \"stops_minutes\": s.get(\"stops_minutes\", 10.0)\n",
        "            }\n",
        "            standardized.append(standard)\n",
        "        session_state = {\"session_id\": session_id, \"shipments\": standardized, \"created\": time.time()}\n",
        "        self.session.sessions[session_id][\"state\"].update(session_state)\n",
        "        self.session.append_history(session_id, {\"actor\": self.name, \"event\": \"intake\", \"data\": standardized, \"time\": time.time()})\n",
        "        self.obs.record_log(trace_id, f\"{self.name}.standardized\", {\"session_id\": session_id, \"shipments_count\": len(standardized)})\n",
        "        # A2A to RouteAnalyzer\n",
        "        msg2 = make_message(self.name, \"RouteAnalyzer\", \"analyze_routes\", {\"session_id\": session_id}, trace_id=trace_id)\n",
        "        await coordinator.send_to_agent(\"RouteAnalyzer\", msg2)\n",
        "\n",
        "\n",
        "class RouteAnalyzerAgent(Agent):\n",
        "    \"\"\"\n",
        "    Calculates baseline metrics and detects anomalies using the LLM as a classifier+explainability tool.\n",
        "    \"\"\"\n",
        "    async def handle_message(self, msg: Dict[str, Any]):\n",
        "        trace_id = msg[\"trace_id\"]\n",
        "        session_id = msg[\"payload\"][\"session_id\"]\n",
        "        self.obs.incr(\"analyze_requests\")\n",
        "        session = self.session.get(session_id)\n",
        "        shipments = session[\"state\"][\"shipments\"]\n",
        "        analysis = []\n",
        "        for s in shipments:\n",
        "            metrics = ToolExecutor.compute_trip_metrics(s[\"path\"], s[\"speed_kmh\"], s[\"stops_minutes\"])\n",
        "            # Simple anomaly heuristics\n",
        "            anomaly = None\n",
        "            if metrics[\"time_h\"] > (len(s[\"path\"]) * 0.1 + 1.5):  # arbitrary heuristic\n",
        "                anomaly = \"high_total_time\"\n",
        "            if metrics[\"fuel_liters\"] > 50:\n",
        "                anomaly = \"high_fuel\"\n",
        "            # Ask LLM for a classification/explanation (simulated)\n",
        "            prompt = f\"Classify trip {s['id']} metrics={metrics}, heuristics anomaly={anomaly}. Provide anomaly label and recommendation.\"\n",
        "            llm_out = await self.llm.send(self.memory.compact_context(), prompt)\n",
        "            structured = llm_out.get(\"structured\", {})\n",
        "            analysis.append({\"id\": s[\"id\"], \"metrics\": metrics, \"heuristic_anomaly\": anomaly, \"llm\": structured})\n",
        "            self.obs.record_log(trace_id, f\"{self.name}.trip_analysis\", {\"id\": s[\"id\"], \"metrics\": metrics, \"llm\": structured})\n",
        "        # store analysis\n",
        "        session[\"state\"][\"analysis\"] = analysis\n",
        "        self.session.append_history(session_id, {\"actor\": self.name, \"event\": \"analysis\", \"data\": analysis, \"time\": time.time()})\n",
        "        # Send to Optimizer\n",
        "        msg2 = make_message(self.name, \"Optimizer\", \"optimize\", {\"session_id\": session_id}, trace_id=trace_id)\n",
        "        await coordinator.send_to_agent(\"Optimizer\", msg2)\n",
        "\n",
        "\n",
        "class OptimizerAgent(Agent):\n",
        "    \"\"\"\n",
        "    Suggests optimizations: reassign stops, suggest route variants, perform fuel-aware tradeoffs.\n",
        "    Implements sequential & parallel behaviors (parallel evaluation of candidate plans).\n",
        "    \"\"\"\n",
        "    async def handle_message(self, msg: Dict[str, Any]):\n",
        "        trace_id = msg[\"trace_id\"]\n",
        "        session_id = msg[\"payload\"][\"session_id\"]\n",
        "        self.obs.incr(\"optimize_requests\")\n",
        "        session = self.session.get(session_id)\n",
        "        analysis = session[\"state\"].get(\"analysis\", [])\n",
        "        # Build candidate optimizations: simple permutations / reassignments\n",
        "        candidates = []\n",
        "        # Candidate 0: do nothing (baseline)\n",
        "        baseline = {\"name\":\"baseline\", \"changes\":[]}\n",
        "        candidates.append(baseline)\n",
        "        # Candidate 1: if any high_idle_time anomaly -> reassign stop to closer vehicle\n",
        "        for a in analysis:\n",
        "            if a[\"heuristic_anomaly\"] or (a[\"llm\"].get(\"anomaly\") is not None):\n",
        "                candidates.append({\"name\": f\"fix_{a['id']}_reassign\", \"changes\":[{\"action\":\"reassign\",\"trip\":a[\"id\"]}]})\n",
        "        # Evaluate candidates in parallel\n",
        "        results = await asyncio.gather(*[self.evaluate_candidate(session, c, trace_id) for c in candidates])\n",
        "        # choose best (by eta reduction and fuel saving)\n",
        "        best = max(results, key=lambda r: (r.get(\"eta_reduction_h\",0) + (r.get(\"fuel_saving_l\",0)/100.0)))\n",
        "        session[\"state\"][\"optimization\"] = {\"candidates\": results, \"best\": best}\n",
        "        self.session.append_history(session_id, {\"actor\": self.name, \"event\": \"optimization\", \"data\": session[\"state\"][\"optimization\"], \"time\": time.time()})\n",
        "        self.obs.record_log(trace_id, f\"{self.name}.best\", {\"best\": best})\n",
        "        # send to Reporter\n",
        "        msg2 = make_message(self.name, \"Reporter\", \"report\", {\"session_id\": session_id}, trace_id=trace_id)\n",
        "        await coordinator.send_to_agent(\"Reporter\", msg2)\n",
        "\n",
        "    async def evaluate_candidate(self, session: Dict[str, Any], candidate: Dict[str, Any], trace_id: str):\n",
        "        # Simulate candidate evaluation. For real deployment plug in route engine / maps API.\n",
        "        await asyncio.sleep(0.2)\n",
        "        shipments = session[\"state\"][\"shipments\"]\n",
        "        # baseline totals\n",
        "        total_km = sum(ToolExecutor.compute_trip_metrics(s[\"path\"], s[\"speed_kmh\"], s[\"stops_minutes\"])[\"km\"] for s in shipments)\n",
        "        total_time_h = sum(ToolExecutor.compute_trip_metrics(s[\"path\"], s[\"speed_kmh\"], s[\"stops_minutes\"])[\"time_h\"] for s in shipments)\n",
        "        total_fuel_l = sum(ToolExecutor.compute_trip_metrics(s[\"path\"], s[\"speed_kmh\"], s[\"stops_minutes\"])[\"fuel_liters\"] for s in shipments)\n",
        "        # apply naive \"improvement\" if candidate has reassign: reduce time by 10% and fuel by 5%\n",
        "        eta_reduction_h = 0.0\n",
        "        fuel_saving_l = 0.0\n",
        "        if candidate[\"name\"] != \"baseline\":\n",
        "            eta_reduction_h = total_time_h * 0.10\n",
        "            fuel_saving_l = total_fuel_l * 0.05\n",
        "        else:\n",
        "            eta_reduction_h = 0.0\n",
        "            fuel_saving_l = 0.0\n",
        "        # ask LLM for explanation of candidate (simulated)\n",
        "        prompt = f\"Evaluate candidate {candidate['name']} with naive metrics: eta_reduction={eta_reduction_h}, fuel_saving={fuel_saving_l}.\"\n",
        "        llm_out = await self.llm.send(self.memory.compact_context(), prompt)\n",
        "        structured = llm_out.get(\"structured\", {})\n",
        "        res = {\"candidate\": candidate, \"eta_reduction_h\": eta_reduction_h, \"fuel_saving_l\": fuel_saving_l, \"llm\": structured}\n",
        "        self.obs.record_log(trace_id, f\"{self.name}.candidate_eval\", {\"candidate\": candidate[\"name\"], \"eta_reduction_h\": eta_reduction_h})\n",
        "        return res\n",
        "\n",
        "\n",
        "class ReporterAgent(Agent):\n",
        "    \"\"\"\n",
        "    Generates the final report and evaluation metrics.\n",
        "    \"\"\"\n",
        "    async def handle_message(self, msg: Dict[str, Any]):\n",
        "        trace_id = msg[\"trace_id\"]\n",
        "        session_id = msg[\"payload\"][\"session_id\"]\n",
        "        session = self.session.get(session_id)\n",
        "        optimization = session[\"state\"].get(\"optimization\", {})\n",
        "        analysis = session[\"state\"].get(\"analysis\", [])\n",
        "        # Build human readable report\n",
        "        best = optimization.get(\"best\", {})\n",
        "        summary = {\n",
        "            \"session_id\": session_id,\n",
        "            \"timestamp\": datetime.utcnow().isoformat(),\n",
        "            \"total_trips\": len(session[\"state\"].get(\"shipments\", [])),\n",
        "            \"best_plan\": best,\n",
        "            \"analysis\": analysis\n",
        "        }\n",
        "        # persist to memory bank\n",
        "        # compute totals for memory\n",
        "        total_time_h = sum(a[\"metrics\"][\"time_h\"] for a in analysis)\n",
        "        total_fuel_l = sum(a[\"metrics\"][\"fuel_liters\"] for a in analysis)\n",
        "        metadata = {\"session_id\": session_id, \"total_time_h\": total_time_h, \"fuel_liters\": total_fuel_l, \"best\": best}\n",
        "        self.memory.record_run(metadata)\n",
        "        self.session.append_history(session_id, {\"actor\": self.name, \"event\": \"report\", \"data\": summary, \"time\": time.time()})\n",
        "        self.obs.record_log(trace_id, f\"{self.name}.final_report\", {\"session_id\": session_id, \"summary\": {\"total_time_h\": total_time_h, \"fuel_liters\": total_fuel_l}})\n",
        "        # print/send report to UI / return in message bus\n",
        "        print(\"\\n=== SupplyChain-Eye Report ===\")\n",
        "        print(json.dumps(summary, indent=2, default=str))\n",
        "        print(\"=== End Report ===\\n\")\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Coordinator (runs agents)\n",
        "# -----------------------\n",
        "\n",
        "class Coordinator:\n",
        "    \"\"\"\n",
        "    Manages agents, message passing, pause/resume, and top-level orchestration.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.session_service = InMemorySessionService()\n",
        "        self.memory = MemoryBank()\n",
        "        self.obs = Observability()\n",
        "        self.llm = DummyLLMClient()  # replace with real implementation\n",
        "        # instantiate agents\n",
        "        self.agents: Dict[str, Agent] = {}\n",
        "        self.loop = asyncio.get_event_loop()\n",
        "        self.tasks = []\n",
        "\n",
        "    def setup_agents(self):\n",
        "        self.agents = {\n",
        "            \"DataIntake\": DataIntakeAgent(\"DataIntake\", self.llm, self.session_service, self.memory, self.obs),\n",
        "            \"RouteAnalyzer\": RouteAnalyzerAgent(\"RouteAnalyzer\", self.llm, self.session_service, self.memory, self.obs),\n",
        "            \"Optimizer\": OptimizerAgent(\"Optimizer\", self.llm, self.session_service, self.memory, self.obs),\n",
        "            \"Reporter\": ReporterAgent(\"Reporter\", self.llm, self.session_service, self.memory, self.obs),\n",
        "        }\n",
        "\n",
        "    async def start(self):\n",
        "        # start all agent run loops\n",
        "        for name, agent in self.agents.items():\n",
        "            t = asyncio.create_task(agent.run())\n",
        "            self.tasks.append(t)\n",
        "        self.obs.record_log(\"coordinator\", \"started\", {\"agents\": list(self.agents.keys())})\n",
        "\n",
        "    async def stop(self):\n",
        "        for a in self.agents.values():\n",
        "            a.running = False\n",
        "        await asyncio.sleep(0.3)\n",
        "        for t in self.tasks:\n",
        "            t.cancel()\n",
        "        self.obs.record_log(\"coordinator\", \"stopped\", {})\n",
        "\n",
        "    async def send_to_agent(self, agent_name: str, msg: Dict[str, Any]):\n",
        "        if agent_name not in self.agents:\n",
        "            raise ValueError(f\"{agent_name} not registered\")\n",
        "        await self.agents[agent_name].send(msg)\n",
        "        self.obs.incr(\"messages_sent\")\n",
        "\n",
        "    def persist_checkpoint(self, session_id: str):\n",
        "        # Save session and memory\n",
        "        session_path = self.session_service.save(session_id)\n",
        "        memory_path = self.memory.filename\n",
        "        self.obs.record_log(session_id, \"checkpoint_saved\", {\"session_path\": session_path, \"memory_path\": memory_path})\n",
        "        return {\"session_path\": session_path, \"memory_path\": memory_path}\n",
        "\n",
        "    def resume_from_checkpoint(self, session_id: str):\n",
        "        self.session_service.load(session_id)\n",
        "        self.obs.record_log(session_id, \"checkpoint_loaded\", {\"session_id\": session_id})\n",
        "\n",
        "    # convenience - send initial dataset\n",
        "    async def ingest(self, payload: Dict[str, Any]):\n",
        "        trace_id = str(uuid.uuid4())\n",
        "        msg = make_message(\"User\", \"DataIntake\", \"ingest\", payload, trace_id=trace_id)\n",
        "        await self.send_to_agent(\"DataIntake\", msg)\n",
        "        return trace_id\n",
        "\n",
        "\n",
        "# global coordinator for ease of A2A\n",
        "coordinator = Coordinator()\n",
        "coordinator.setup_agents()\n",
        "\n",
        "# -----------------------\n",
        "# Agent Evaluation Module\n",
        "# -----------------------\n",
        "\n",
        "def evaluate_session_metrics(memory: MemoryBank, last_n: int = 5) -> Dict[str, Any]:\n",
        "    \"\"\"Simple evaluator returning compacted statistics for judges.\"\"\"\n",
        "    ctx = memory.compact_context(last_n=last_n)\n",
        "    return {\"compact\": ctx, \"runs_stored\": len(memory.store.get(\"runs\", []))}\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Demo / Example usage\n",
        "# -----------------------\n",
        "\n",
        "SAMPLE_PAYLOAD = {\n",
        "    \"shipments\": [\n",
        "        {\"id\":\"S1\", \"path\":[(12.9716,77.5946),(12.9352,77.6245),(12.9081,77.6476)], \"vehicle\":\"truckA\", \"speed_kmh\":40.0, \"stops_minutes\":12},\n",
        "        {\"id\":\"S2\", \"path\":[(12.9716,77.5946),(13.0358,77.5970),(13.0500,77.6000)], \"vehicle\":\"truckB\", \"speed_kmh\":45.0, \"stops_minutes\":8}\n",
        "    ],\n",
        "    \"constraints\": {\"max_fuel_l\": 100}\n",
        "}\n",
        "\n",
        "\n",
        "async def demo_run():\n",
        "    await coordinator.start()\n",
        "    trace = await coordinator.ingest({\"shipments\": SAMPLE_PAYLOAD[\"shipments\"]})\n",
        "    # allow some time for pipeline to process\n",
        "    await asyncio.sleep(2.0)\n",
        "    # checkpoint session for pause/resume demo\n",
        "    # get session id from last created in service\n",
        "    last_session_id = list(coordinator.session_service.sessions.keys())[-1]\n",
        "    cp = coordinator.persist_checkpoint(last_session_id)\n",
        "    print(\"Checkpoint saved:\", cp)\n",
        "    # run evaluator\n",
        "    eval_res = evaluate_session_metrics(coordinator.memory, last_n=3)\n",
        "    print(\"Evaluation compact:\", eval_res)\n",
        "    # stop agents\n",
        "    await coordinator.stop()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        asyncio.run(demo_run())\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Interrupted\")\n"
      ]
    }
  ]
}